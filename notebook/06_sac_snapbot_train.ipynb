{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436b0ffd-890b-477c-859d-7a1965ab08d9",
   "metadata": {},
   "source": [
    "### `Soft Actor-Critic` using `Snapbot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966cc7e-a2c5-4349-b605-77de1eddd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,mujoco\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../package/helper/')\n",
    "sys.path.append('../package/mujoco_usage/')\n",
    "sys.path.append('../package/gym/')\n",
    "sys.path.append('../package/rl/')\n",
    "from mujoco_parser import *\n",
    "from slider import *\n",
    "from utility import *\n",
    "from snapbot_env import *\n",
    "from sac import *\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a258f0b-3700-4131-8dd8-297c4ea84df8",
   "metadata": {},
   "source": [
    "#### Parse `Snapbot` gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a686f-4273-4576-a22c-8c0a294afbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xml_path = '../asset/snapbot/scene_snapbot.xml'\n",
    "env = MuJoCoParserClass(name='Snapbot',rel_xml_path=xml_path,verbose=True)\n",
    "gym = SnapbotGymClass(\n",
    "    env = env,\n",
    "    HZ  = 50,\n",
    "    history_total_sec = 0.2,\n",
    "    history_intv_sec  = 0.1,\n",
    "    VERBOSE =True,\n",
    ")\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ef748-52f2-4393-87d5-1fd8a0b3deed",
   "metadata": {},
   "source": [
    "#### `SAC` configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26839616-f629-4d84-8f90-be42dc2796a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episode         = 1000 # number of total episodes (rollouts)\n",
    "max_epi_sec       = 5.0 # maximum episode length in second (IMPORTANT)\n",
    "max_epi_tick      = int(max_epi_sec*gym.HZ) # maximum episode length in tick\n",
    "n_warmup_epi      = 10 # number of warm-up episodes\n",
    "buffer_limit      = 50000 # 50000\n",
    "buffer_warmup     = buffer_limit // 5\n",
    "init_alpha        = 0.1\n",
    "max_torque        = 2.0\n",
    "# Update\n",
    "lr_actor          = 0.0005 # 0.0002\n",
    "lr_alpha          = 0.0001 # 0.0003\n",
    "lr_critic         = 0.0001\n",
    "n_update_per_tick = 1 # number of updates per tick\n",
    "batch_size        = 256\n",
    "gamma             = 0.99\n",
    "tau               = 0.005\n",
    "# Debug\n",
    "print_every       = 50\n",
    "eval_every        = 50\n",
    "save_every        = 50\n",
    "RENDER_EVAL       = False # False\n",
    "print (\"n_episode:[%d], max_epi_sec:[%.2f], max_epi_tick:[%d]\"%\n",
    "       (n_episode,max_epi_sec,max_epi_tick))\n",
    "print (\"n_warmup_epi:[%d], buffer_limit:[%.d], buffer_warmup:[%d]\"%\n",
    "       (n_warmup_epi,buffer_limit,buffer_warmup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42393c-131f-4769-b110-f88c3fdd610c",
   "metadata": {},
   "source": [
    "#### Initialize networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69ae65-97f7-4d84-984a-f74752c0faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # cpu / mps / cuda\n",
    "replay_buffer = ReplayBufferClass(buffer_limit, device=device)\n",
    "actor_arg = {'obs_dim':gym.o_dim,'h_dims':[256,256],'out_dim':gym.a_dim,\n",
    "             'max_out':max_torque,'init_alpha':init_alpha,'lr_actor':lr_actor,\n",
    "             'lr_alpha':lr_alpha,'device':device}\n",
    "critic_arg = {'obs_dim':gym.o_dim,'a_dim':gym.a_dim,'h_dims':[256,256],'out_dim':1,\n",
    "              'lr_critic':lr_critic,'device':device}\n",
    "actor           = ActorClass(**actor_arg).to(device)\n",
    "critic_one      = CriticClass(**critic_arg).to(device)\n",
    "critic_two      = CriticClass(**critic_arg).to(device)\n",
    "critic_one_trgt = CriticClass(**critic_arg).to(device)\n",
    "critic_two_trgt = CriticClass(**critic_arg).to(device)\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a57c1a-d9d3-44c9-91f0-b92df844f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify floor friction priority\n",
    "env.model.geom('floor').priority = 1 # 0=>1\n",
    "print (\"Floor priority:%s\"%(env.model.geom('floor').priority))\n",
    "gym.env.ctrl_ranges[:,0] = -max_torque\n",
    "gym.env.ctrl_ranges[:,1] = +max_torque\n",
    "print (\"gym.env.ctrl_ranges:\\n\",gym.env.ctrl_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbfb24-7e9c-4a9e-a89f-72e3fcfab8c4",
   "metadata": {},
   "source": [
    "#### Train using `SAC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637ea6c-e08f-4e8f-a822-e1073fa6511d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REMOVE_PREV_FILES = False # remove previous files\n",
    "\n",
    "# Loop\n",
    "np.random.seed(seed=0) # fix seed\n",
    "print (\"Start training.\")\n",
    "for epi_idx in range(n_episode+1): # for each episode\n",
    "    zero_to_one = epi_idx/n_episode\n",
    "    one_to_zero = 1-zero_to_one\n",
    "    # Reset gym\n",
    "    s = gym.reset()\n",
    "    # Loop\n",
    "    USE_RANDOM_POLICY = (np.random.rand()<(0.1*one_to_zero)) or (epi_idx < n_warmup_epi)\n",
    "    reward_total,reward_forward = 0.0,0.0\n",
    "    for tick in range(max_epi_tick): # for each tick in an episode\n",
    "        if USE_RANDOM_POLICY:\n",
    "            a_np = gym.sample_action()\n",
    "        else:\n",
    "            a,log_prob = actor(np2torch(s,device=device))\n",
    "            a_np = torch2np(a)\n",
    "        # Step\n",
    "        s_prime,reward,done,info = gym.step(a_np,max_time=max_epi_sec)\n",
    "        replay_buffer.put((s,a_np,reward,s_prime,done))\n",
    "        reward_total += reward \n",
    "        reward_forward += info['r_forward']\n",
    "        s = s_prime\n",
    "        if done is True: break # terminate condition\n",
    "        \n",
    "        # Replay buffer\n",
    "        if replay_buffer.size() > buffer_warmup:\n",
    "             for _ in range(n_update_per_tick): \n",
    "                mini_batch = replay_buffer.sample(batch_size)\n",
    "                # Update critics\n",
    "                td_target = get_target(\n",
    "                    actor,\n",
    "                    critic_one_trgt,\n",
    "                    critic_two_trgt,\n",
    "                    gamma      = gamma,\n",
    "                    mini_batch = mini_batch,\n",
    "                    device     = device,\n",
    "                )\n",
    "                critic_one.train(td_target,mini_batch)\n",
    "                critic_two.train(td_target,mini_batch)\n",
    "                # Update actor\n",
    "                actor.train(\n",
    "                    critic_one,\n",
    "                    critic_two,\n",
    "                    target_entropy = -gym.a_dim,\n",
    "                    mini_batch     = mini_batch,\n",
    "                )\n",
    "                # Soft update of critics\n",
    "                critic_one.soft_update(tau=tau,net_target=critic_one_trgt)\n",
    "                critic_two.soft_update(tau=tau,net_target=critic_two_trgt)\n",
    "\n",
    "    # Compute x_diff\n",
    "    x_diff = gym.env.get_p_body('torso')[0]\n",
    "    \n",
    "    # Print\n",
    "    if (epi_idx%print_every)==0:\n",
    "        epi_tick = tick\n",
    "        print (\"[%d/%d][%.1f%%]\"%(epi_idx,n_episode,100.0*(epi_idx/n_episode)))\n",
    "        print (\"  reward:[%.1f] x_diff:[%.3f] epi_len:[%d/%d] buffer_size:[%d] alpha:[%.2f]\"%\n",
    "               (reward_total,x_diff,epi_tick,max_epi_tick,\n",
    "                replay_buffer.size(),actor.log_alpha.exp()))\n",
    "    \n",
    "    # Evaluation\n",
    "    if (epi_idx%eval_every)==0:\n",
    "        if RENDER_EVAL: gym.init_viewer()\n",
    "        s = gym.reset()\n",
    "        reward_total = 0.0\n",
    "        for tick in range(max_epi_tick):\n",
    "            a,_ = actor(np2torch(s,device=device),SAMPLE_ACTION=False)\n",
    "            s_prime,reward,done,info = gym.step(torch2np(a),max_time=max_epi_sec)\n",
    "            reward_total += reward\n",
    "            if RENDER_EVAL and ((tick%5) == 0):\n",
    "                gym.render(\n",
    "                    TRACK_TORSO      = True,\n",
    "                    PLOT_WORLD_COORD = True,\n",
    "                    PLOT_TORSO_COORD = True,\n",
    "                    PLOT_SENSOR      = True,\n",
    "                    PLOT_CONTACT     = True,\n",
    "                    PLOT_TIME        = True,\n",
    "                )\n",
    "            s = s_prime\n",
    "            if RENDER_EVAL:\n",
    "                if not gym.is_viewer_alive(): break\n",
    "        if RENDER_EVAL: gym.close_viewer()\n",
    "        x_diff = gym.env.get_p_body('torso')[0]\n",
    "        print (\"  [Eval] reward:[%.3f] x_diff:[%.3f] epi_len:[%d/%d]\"%\n",
    "               (reward_total,x_diff,tick,max_epi_tick))\n",
    "\n",
    "    # Save network\n",
    "    if (epi_idx%save_every)==0:\n",
    "        pth_path = './result/weights/sac_%s/episode_%d.pth'%(gym.name.lower(),epi_idx)\n",
    "        dir_path = os.path.dirname(pth_path)\n",
    "        if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
    "        if (epi_idx == 0) and REMOVE_PREV_FILES: # remove all existing files\n",
    "            files = os.listdir(path=dir_path)\n",
    "            print (\"  [Save] Remove existing [%d] pth files.\"%(len(files)))\n",
    "            for file in files: os.remove(os.path.join(dir_path,file))\n",
    "        torch.save(actor.state_dict(),pth_path)\n",
    "        print (\"  [Save] [%s] saved.\"%(pth_path))\n",
    "\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272e03d-f38b-4487-8b0c-c36a9f3c4f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
